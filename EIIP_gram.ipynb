{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg6wW7wibrSu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import io\n",
        "import os\n",
        "import torchtext\n",
        "\n",
        "\n",
        "def tokenizator(seq):\n",
        "    reprezentacja = []\n",
        "    for i in range(len(seq)-1):\n",
        "        reprezentacja.append(seq[i:(i+2)])\n",
        "    return reprezentacja\n",
        "\n",
        "\n",
        "class T_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True) #LSTM\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)  #przeksztalcenie liniowe\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)\n",
        "        x = torch.tensor(x)\n",
        "        x = torch.tensor(x, dtype=torch.float)\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size) #początkowy  h0\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size) #początkowy c0\n",
        "        out, _ = self.lstm(x, (h0, c0))  #LSTM\n",
        "        out = self.fc(out[:, -1, :]) #przeksztlcam jeszcze liniowo ostatni output\n",
        "        return out\n",
        "\n",
        "#Funkcja wyznaczająca dokładność predykcji:\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    data_loader.create_batches()\n",
        "    correct, total = 0, 0  #ile ok, ile wszystkich\n",
        "\n",
        "    for num, batch in enumerate(data_loader): #przechodzi dane\n",
        "\n",
        "        # Put all example.text of batch in single array.\n",
        "        batch_text = list(batch)[0]\n",
        "        labels = list(batch)[1]\n",
        "        x = torch.tensor(batch_text[0])\n",
        "        output = model(x) #co mowi model\n",
        "        pred = output.max(1, keepdim=True)[1]  #ktora kategoria\n",
        "        #print(pred)\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        #print(correct)\n",
        "        total += labels.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "#funkcja do trenowania modelu\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss() #funkcja kosztu\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #optymalizator modelu\n",
        "    losses, train_acc, valid_acc, epochs = [], [], [], []  #cztery listy na wartosci funkcji kosztu, dokladnosc na zbiorze testowym i walidacyjnym, numer epoki\n",
        "    \n",
        "    for epoch in range(num_epochs): #przechodz kolejne epoki (iteracje)\n",
        "        \n",
        "        #train_loader.create_batches()\n",
        "        \n",
        "        for num, batch in enumerate(train_loader): #.batches):\n",
        "            \n",
        "            # Put all example.text of batch in single array.\n",
        "            batch_text = list(batch)[0]\n",
        "            batch_label = list(batch)[1]\n",
        "            optimizer.zero_grad()\n",
        "            x = torch.tensor(batch_text[0])\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, batch_label)  #wartosc funkcji kosztu - porownanie tego co mowi model, a tego jak jest\n",
        "            loss.backward()                  #pochodna po funkcji kosztu\n",
        "            optimizer.step()                 #aktualizacja parametrow\n",
        "\n",
        "            \n",
        "        losses.append(float(loss))           #zapisz aktualną wartosc funkcji kosztu\n",
        "        epochs.append(epoch)                 #zapisz aktualny numer epoki\n",
        "        train_acc.append(get_accuracy(model, torchtext_train_dataloader))   #dokladnosc na zbiorze treningowym\n",
        "        valid_acc.append(get_accuracy(model, torchtext_valid_dataloader))   #dokladnosc na zbiorze walidacyjnym\n",
        "        print(f'Epoch number: {epoch+1} | Loss value: {loss} | Train accuracy: {round(train_acc[-1],3)} | Valid accuracy: {round(valid_acc[-1],3)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gram_minus_ess_new.txt','r') as f:\n",
        "    e_file = f.read()\n",
        "\n",
        "with open('gram_minus_ness_new.txt','r') as f1:\n",
        "    n_file = f1.read()\n",
        "    \n",
        "x = re.split('>(DEG\\d+)\\n([ATGC\\n]+)', e_file)\n",
        "v = [i.replace('\\n','') for i in x]\n",
        "\n",
        "x2 = re.split('>(DNEG\\d+)\\n([ATGC\\n]+)', n_file)\n",
        "v2 = [i.replace('\\n','') for i in x2]\n",
        "\n",
        "e_names = []\n",
        "e_seq = []\n",
        "\n",
        "for i in v:\n",
        "    match1= re.search('^[ATGC]+$',i)\n",
        "    match2= re.search('>?DEG',i)\n",
        "    if match2:\n",
        "        if not 'available' in i:\n",
        "            e_names.append(i)\n",
        "    else:\n",
        "        if match1:\n",
        "            e_seq.append(i)\n",
        "\n",
        "n_names = []\n",
        "n_seq = []\n",
        "\n",
        "for i in v2:\n",
        "    match1= re.search('^[ATGC]+$',i)\n",
        "    match2= re.search('>?DNEG',i)\n",
        "    if match2:\n",
        "        if not 'available' in i:\n",
        "            n_names.append(i)\n",
        "    else:\n",
        "        if match1:\n",
        "            n_seq.append(i)"
      ],
      "metadata": {
        "id": "6ze1mjtQb8in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gram_plus_ess_new.txt','r') as f:\n",
        "    e_file = f.read()\n",
        "\n",
        "with open('gram_plus_ness_new.txt','r') as f1:\n",
        "    n_file = f1.read()\n",
        "    \n",
        "x = re.split('>(DEG\\d+)\\n([ATGC\\n]+)', e_file)\n",
        "v = [i.replace('\\n','') for i in x]\n",
        "\n",
        "x2 = re.split('>(DNEG\\d+)\\n([ATGC\\n]+)', n_file)\n",
        "v2 = [i.replace('\\n','') for i in x2]\n",
        "\n",
        "e_names2 = []\n",
        "e_seq2 = []\n",
        "\n",
        "for i in v:\n",
        "    match1= re.search('^[ATGC]+$',i)\n",
        "    match2= re.search('>?DEG',i)\n",
        "    if match2:\n",
        "        if not 'available' in i:\n",
        "            e_names2.append(i)\n",
        "    else:\n",
        "        if match1:\n",
        "            e_seq2.append(i)\n",
        "\n",
        "n_names2 = []\n",
        "n_seq2 = []\n",
        "\n",
        "for i in v2:\n",
        "    match1= re.search('^[ATGC]+$',i)\n",
        "    match2= re.search('>?DNEG',i)\n",
        "    if match2:\n",
        "        if not 'available' in i:\n",
        "            n_names2.append(i)\n",
        "    else:\n",
        "        if match1:\n",
        "            n_seq2.append(i)"
      ],
      "metadata": {
        "id": "Fs_KbsZncAvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_with_label(seq, label):\n",
        "    \n",
        "    words_labels = []\n",
        "    \n",
        "    for s in seq:\n",
        "            \n",
        "        words_labels.append([label, s])\n",
        "            \n",
        "    return words_labels"
      ],
      "metadata": {
        "id": "gYW3r-GCegDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_data = seq_with_label(e_seq, 'e')\n",
        "ne_data = seq_with_label(n_seq, 'n')"
      ],
      "metadata": {
        "id": "8c1cjpTccDbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_data2 = seq_with_label(e_seq2, 'e')\n",
        "ne_data2 = seq_with_label(n_seq2, 'n')"
      ],
      "metadata": {
        "id": "P1HGh5FJcFJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e_len = len(e_data2)\n",
        "\n",
        "data = e_data[:e_len] + ne_data[:e_len]"
      ],
      "metadata": {
        "id": "mi26lIyLcFpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "P73Yl1fncJMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = e_data2[:e_len] + ne_data2[:e_len]"
      ],
      "metadata": {
        "id": "SHr6R2QOcMpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data2)"
      ],
      "metadata": {
        "id": "Ig806-dVcLta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "PeNg8nkScQNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('genes_with_labels.tsv', 'wt') as file:\n",
        "    tsv_writer = csv.writer(file, delimiter='\\t')\n",
        "    for elem in data:\n",
        "      tsv_writer.writerow(elem)"
      ],
      "metadata": {
        "id": "s5LkUM72cfmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('genes_with_labels2.tsv', 'wt') as file:\n",
        "    tsv_writer = csv.writer(file, delimiter='\\t')\n",
        "    for elem in data2:\n",
        "      tsv_writer.writerow(elem)"
      ],
      "metadata": {
        "id": "oQsmDIPFc4-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install torchtext==0.9\n"
      ],
      "metadata": {
        "id": "7lbLPqUDeo9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = torchtext.legacy.data.Field(sequential=True,      \n",
        "                                  tokenize=tokenizator, \n",
        "                                  include_lengths=True, \n",
        "                                  batch_first=True,\n",
        "                                  use_vocab=True)      \n",
        "\n",
        "label_field = torchtext.legacy.data.Field(sequential=False,    \n",
        "                                   use_vocab=False,     \n",
        "                                   is_target=True,      \n",
        "                                   batch_first=True,\n",
        "                                   preprocessing=lambda x: int(x == 'e')) \n",
        "\n",
        "\n",
        "fields = [('label', label_field), ('seq', text_field)]"
      ],
      "metadata": {
        "id": "8FV_r1wDcjSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uj = torchtext.legacy.data.TabularDataset('genes_with_labels.tsv', \"tsv\", fields)\n",
        "dod = torchtext.legacy.data.TabularDataset('genes_with_labels2.tsv', \"tsv\", fields)\n",
        "\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "custom_embeddings = vocab.Vectors(name = 'eip4.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2rj2p7CdGpY",
        "outputId": "b8167601-8a6c-42b2-f5a2-1083c97dd619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 15/16 [00:00<00:00, 14125.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_field.build_vocab(uj, vectors = custom_embeddings)\n",
        "\n",
        "torchtext_train_dataloader = torchtext.legacy.data.BucketIterator(uj,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.seq), \n",
        "                                           sort_within_batch=True,        \n",
        "                                           repeat=False)"
      ],
      "metadata": {
        "id": "C1K1vv4sdfMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_field.build_vocab(dod, vectors = custom_embeddings)\n",
        "\n",
        "torchtext_train_dataloader2 = torchtext.legacy.data.BucketIterator(dod,\n",
        "                                           batch_size=32,\n",
        "                                           sort_key=lambda x: len(x.seq), \n",
        "                                           sort_within_batch=True,        \n",
        "                                           repeat=False)"
      ],
      "metadata": {
        "id": "z6gb7ZGydmH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "bw-4WGSrdpPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open(\"model_batch16_hidden25_new\", 'rb'))"
      ],
      "metadata": {
        "id": "GdpysZNldtKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVPhoT0QeJI7",
        "outputId": "1d5238d0-b6c7-4934-9ea1-6c59db86295e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T_LSTM(\n",
              "  (lstm): LSTM(1, 25, batch_first=True)\n",
              "  (fc): Linear(in_features=25, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bakterie Gram ujemne"
      ],
      "metadata": {
        "id": "6wek3EiKeL5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(model, torchtext_train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQkDN2_feKJY",
        "outputId": "a16c9a23-c73d-4e67-a309-7dcef993b6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8f475233b7b6>:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(batch_text[0])\n",
            "<ipython-input-1-8f475233b7b6>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n",
            "<ipython-input-1-8f475233b7b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7430568161190779"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bakterie Gram dodatnie"
      ],
      "metadata": {
        "id": "ODy1qzFteO9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(model, torchtext_train_dataloader2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJDgHxL3eOiR",
        "outputId": "93e9039e-178d-4d1c-a5b1-d0709a29ac03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8f475233b7b6>:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(batch_text[0])\n",
            "<ipython-input-1-8f475233b7b6>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n",
            "<ipython-input-1-8f475233b7b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7158286440370303"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}